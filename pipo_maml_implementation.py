# -*- coding: utf-8 -*-
"""PIPO MAML Implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dhBQ8muHJoaD-d2ryuQSmmuJMNH3mcZq
"""

import torch
from torch import nn, optim

class MAMLModel(nn.Module):
    def __init__(self, input_size, output_size):
        super(MAMLModel, self).__init__()
        self.layer1 = nn.Linear(input_size, 64)
        self.layer2 = nn.Linear(64, 32)
        self.layer3 = nn.Linear(32, output_size)

    def forward(self, x):
        x = torch.relu(self.layer1(x))
        x = torch.relu(self.layer2(x))
        x = self.layer3(x)
        return x

    def clone(self):
        cloned_model = MAMLModel(self.layer1.in_features, self.layer3.out_features)
        cloned_model.load_state_dict(self.state_dict())
        return cloned_model

def maml_train(model, tasks, inner_lr=0.01, meta_lr=0.001, inner_steps=5, meta_steps=100):
    meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)

    for step in range(meta_steps):
        meta_loss = 0.
    for task in tasks:
        task_model = model.clone()
        inner_optimizer = optim.SGD(task_model.parameters(), lr=inner_lr)

        for _ in range(inner_steps):
            predictions = task_model(task['input'])
            loss = nn.MSELoss()(predictions, task['output'])
            inner_optimizer.zero_grad()
            loss.backward()
            inner_optimizer.step()

        # Compute loss for meta-update
        predictions = model(task['input'])
        loss = nn.MSELoss()(predictions, task['output'])
        meta_loss += loss

    meta_optimizer.zero_grad()
    meta_loss.backward()
    meta_optimizer.step()

!pip install gymnasium stable-baselines3 torch

import gymnasium as gym
from gymnasium import spaces
import numpy as np

class CustomTradingEnv(gym.Env):
    def __init__(self, data):
        super(CustomTradingEnv, self).__init__()
        self.data = data
        self.action_space = spaces.Discrete(3)  # Buy, Hold, Sell
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(data.shape[1],), dtype=np.float32)
        self.current_step = 0
        self.balance = 10000  # initial balance
        self.shares_held = 0
        self.current_price = 0
        self.buy_prices = []
        self.sell_prices = []
        self.buy_indices = []
        self.sell_indices = []
        self.actions_log = []

    def reset(self, seed=None, options=None):
        if seed is not None:
            self.np_random, seed = gym.utils.seeding.np_random(seed)
        self.current_step = 0
        self.balance = 10000  # reset balance
        self.shares_held = 0
        self.current_price = self.data.iloc[self.current_step]['Close']
        self.buy_prices = []
        self.sell_prices = []
        self.buy_indices = []
        self.sell_indices = []
        self.actions_log = []
        return self._next_observation(), {}

    def _next_observation(self):
        return self.data.iloc[self.current_step].values

    def step(self, action):
        self.current_price = self.data.iloc[self.current_step]['Close']

        if action == 0:  # Buy
            shares_to_buy = self.balance // self.current_price
            self.shares_held += shares_to_buy
            self.balance -= shares_to_buy * self.current_price
            self.buy_prices.append(self.current_price)
            self.buy_indices.append(self.current_step)
            self.actions_log.append(f"Step {self.current_step}: Buy at {self.current_price}")

        elif action == 2:  # Sell
            self.balance += self.shares_held * self.current_price
            self.sell_prices.append(self.current_price)
            self.sell_indices.append(self.current_step)
            self.shares_held = 0
            self.actions_log.append(f"Step {self.current_step}: Sell at {self.current_price}")

        self.current_step += 1
        done = self.current_step >= len(self.data) - 1

        if done:
            self.balance += self.shares_held * self.current_price
            self.shares_held = 0

        reward = self.balance - 10000  # Profit
        terminated = done
        truncated = False
        info = {}

        return self._next_observation(), reward, terminated, truncated, info

    def render(self, mode='human'):
        profit = self.balance + self.shares_held * self.current_price - 10000
        print(f'Step: {self.current_step}, Balance: {self.balance}, Shares held: {self.shares_held}, Profit: {profit}')

!pip install yfinance
import yfinance as yf

tickers = ['AAPL', 'ISRG', 'TPR', 'AMZN']
data = {}

for ticker in tickers:
    stock_data = yf.download(ticker, start="2021-01-01", end="2024-08-22")
    data[ticker] = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]

tasks = []

for ticker in tickers:
    stock_data = data[ticker]
    input_data = torch.tensor(stock_data[['Open', 'High', 'Low', 'Close', 'Volume']].values, dtype=torch.float32)
    output_data = torch.tensor(stock_data[['Close']].values, dtype=torch.float32)
    tasks.append({'input': input_data, 'output': output_data})

maml_model = MAMLModel(input_size=5, output_size=1)
maml_train(maml_model, tasks, inner_lr=0.01, meta_lr=0.001, inner_steps=5, meta_steps=100)

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

env = DummyVecEnv([lambda: CustomTradingEnv(data['AAPL'])])
env = DummyVecEnv([lambda: CustomTradingEnv(data['ISRG'])])
env = DummyVecEnv([lambda: CustomTradingEnv(data['TPR'])])
env = DummyVecEnv([lambda: CustomTradingEnv(data['AMZN'])])

model = PPO('MlpPolicy', env, verbose=1)
model.learn(total_timesteps=10000)
model.save('ppo_stock_trading')

envs={}
for ticker in tickers:
    envs[ticker] = CustomTradingEnv(data[ticker])

for ticker in tickers:
    print(f"Backtesting on {ticker}")
    env = envs[ticker]
    obs, _ = env.reset()

    for i in range(len(data[ticker])):
        action, _ = model.predict(obs)
        obs, reward, done, _, _ = env.step(action)
        env.render()

        if done:
            break

import matplotlib.pyplot as plt

ticker = 'AAPL'
stock_data = data[ticker]
env = envs[ticker]

plt.figure(figsize=(12, 6))
plt.plot(stock_data['Close'], label=f'{ticker} Close Price', color='blue')

plt.title(f'{ticker} Trading Signals')
plt.legend()
plt.show()

envs={}
for ticker in tickers:
    envs[ticker] = CustomTradingEnv(data[ticker])

for ticker in tickers:
    print(f"Backtesting on {ticker}")
    env = envs[ticker]
    obs, _ = env.reset()

    for i in range(len(data[ticker])):
        action, _ = model.predict(obs)
        obs, reward, done, _, _ = env.step(action)
        env.render()

        if done:
            break

import matplotlib.pyplot as plt

ticker = 'ISRG'
stock_data = data[ticker]
env = envs[ticker]

plt.figure(figsize=(12, 6))
plt.plot(stock_data['Close'], label=f'{ticker} Close Price', color='blue')

plt.title(f'{ticker} Trading Signals')
plt.legend()
plt.show()

envs={}
for ticker in tickers:
    envs[ticker] = CustomTradingEnv(data[ticker])

for ticker in tickers:
    print(f"Backtesting on {ticker}")
    env = envs[ticker]
    obs, _ = env.reset()

    for i in range(len(data[ticker])):
        action, _ = model.predict(obs)
        obs, reward, done, _, _ = env.step(action)
        env.render()

        if done:
            break

import matplotlib.pyplot as plt

ticker = 'TPR'
stock_data = data[ticker]
env = envs[ticker]

plt.figure(figsize=(12, 6))
plt.plot(stock_data['Close'], label=f'{ticker} Close Price', color='blue')

plt.title(f'{ticker} Trading Signals')
plt.legend()
plt.show()

envs={}
for ticker in tickers:
    envs[ticker] = CustomTradingEnv(data[ticker])

for ticker in tickers:
    print(f"Backtesting on {ticker}")
    env = envs[ticker]
    obs, _ = env.reset()

    for i in range(len(data[ticker])):
        action, _ = model.predict(obs)
        obs, reward, done, _, _ = env.step(action)
        env.render()

        if done:
            break

import matplotlib.pyplot as plt

ticker = 'AMZN'
stock_data = data[ticker]
env = envs[ticker]

plt.figure(figsize=(12, 6))
plt.plot(stock_data['Close'], label=f'{ticker} Close Price', color='blue')

plt.title(f'{ticker} Trading Signals')
plt.legend()
plt.show()